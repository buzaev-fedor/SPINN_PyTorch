{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you're running this on Google Colab, please uncomment and run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1660882519921,
     "user": {
      "displayName": "Seungtae Nam",
      "userId": "06693906068580730486"
     },
     "user_tz": -540
    },
    "id": "KoC-hLN4Oliv"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lOqc5OoSN_5M"
   },
   "source": [
    "## 1. SPINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1660882524486,
     "user": {
      "displayName": "Seungtae Nam",
      "userId": "06693906068580730486"
     },
     "user_tz": -540
    },
    "id": "3lmf86_ON_5N"
   },
   "outputs": [],
   "source": [
    "class SPINN(nn.Module):\n",
    "    def __init__(self, features, alpha=0.05):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.alpha = alpha  # коэффициент диффузии\n",
    "        \n",
    "        # Создаем слои для трех координат (t, x, y)\n",
    "        self.networks = nn.ModuleList([\n",
    "            self._build_network() for _ in range(3)\n",
    "        ])\n",
    "        \n",
    "        # Слои для объединения выходов\n",
    "        self.combine_layer1 = nn.Linear(features[-1] * 2, features[-1])\n",
    "        self.combine_layer2 = nn.Linear(features[-1] * 2, features[-1])\n",
    "        self.final_layer = nn.Linear(features[-1], 1)\n",
    "        self.activation = nn.Tanh()\n",
    "    \n",
    "    def _build_network(self):\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(1, self.features[0]))\n",
    "        layers.append(nn.Tanh())\n",
    "        \n",
    "        for i in range(len(self.features) - 2):\n",
    "            layers.append(nn.Linear(self.features[i], self.features[i + 1]))\n",
    "            layers.append(nn.Tanh())\n",
    "            \n",
    "        layers.append(nn.Linear(self.features[-2], self.features[-1]))\n",
    "        layers.append(nn.Tanh())\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _ensure_2d(self, x):\n",
    "        if x.dim() == 1:\n",
    "            return x.unsqueeze(1)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, t, x, y):\n",
    "        # Преобразуем входы в 2D тензоры [batch_size, 1]\n",
    "        t = self._ensure_2d(t)\n",
    "        x = self._ensure_2d(x)\n",
    "        y = self._ensure_2d(y)\n",
    "        \n",
    "        # Пропускаем через отдельные сети\n",
    "        t_features = self.networks[0](t)\n",
    "        x_features = self.networks[1](x)\n",
    "        y_features = self.networks[2](y)\n",
    "        \n",
    "        combined = torch.cat([t_features, x_features], dim=1)\n",
    "        combined = self.activation(self.combine_layer1(combined))\n",
    "        \n",
    "        combined = torch.cat([combined, y_features], dim=1)\n",
    "        combined = self.activation(self.combine_layer2(combined))\n",
    "        \n",
    "        # Финальный слой\n",
    "        output = self.final_layer(combined)\n",
    "        return output.squeeze(-1)\n",
    "\n",
    "\n",
    "class DiffusionLoss:\n",
    "    def __init__(self, model, alpha=None):\n",
    "        self.model = model\n",
    "        self.alpha = alpha if alpha is not None else model.alpha\n",
    "\n",
    "    def residual_loss(self, t, x, y):\n",
    "        t.requires_grad_(True)\n",
    "        x.requires_grad_(True)\n",
    "        y.requires_grad_(True)\n",
    "        \n",
    "        u = self.model(t, x, y)\n",
    "        \n",
    "        # Производная по времени\n",
    "        ut = torch.autograd.grad(\n",
    "            u.sum(), t, \n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        # Производные по x\n",
    "        ux = torch.autograd.grad(\n",
    "            u.sum(), x,\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        uxx = torch.autograd.grad(\n",
    "            ux.sum(), x,\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        # Производные по y\n",
    "        uy = torch.autograd.grad(\n",
    "            u.sum(), y,\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        uyy = torch.autograd.grad(\n",
    "            uy.sum(), y,\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        # Уравнение диффузии: ut - alpha * (uxx + uyy) = 0\n",
    "        residual = ut - self.alpha * (uxx + uyy)\n",
    "        return torch.mean(residual**2)\n",
    "\n",
    "    def initial_loss(self, t, x, y, u_true):\n",
    "        \"\"\"Вычисляет ошибку в начальных условиях.\"\"\"\n",
    "        u_pred = self.model(t, x, y)\n",
    "        return torch.mean((u_pred - u_true)**2)\n",
    "\n",
    "    def boundary_loss(self, tb_list, xb_list, yb_list):\n",
    "        \"\"\"\n",
    "        Вычисляет ошибку на границе (нулевые граничные условия).\n",
    "        \n",
    "        Args:\n",
    "            tb_list, xb_list, yb_list: списки тензоров для границ\n",
    "        \"\"\"\n",
    "        loss = 0.0\n",
    "        \n",
    "        for i in range(len(tb_list)):\n",
    "            tb = tb_list[i]\n",
    "            xb = xb_list[i]\n",
    "            yb = yb_list[i]\n",
    "            \n",
    "            # Проверяем размеры и корректируем их при необходимости\n",
    "            if tb.shape[0] == 1 and xb.shape[0] > 1:\n",
    "                # Растягиваем tb до размера xb\n",
    "                tb = tb.expand(xb.shape)\n",
    "            elif xb.shape[0] == 1 and tb.shape[0] > 1:\n",
    "                # Растягиваем xb до размера tb\n",
    "                xb = xb.expand(tb.shape)\n",
    "                \n",
    "            if tb.shape[0] == 1 and yb.shape[0] > 1:\n",
    "                # Растягиваем tb до размера yb\n",
    "                tb = tb.expand(yb.shape)\n",
    "            elif yb.shape[0] == 1 and tb.shape[0] > 1:\n",
    "                # Растягиваем yb до размера tb\n",
    "                yb = yb.expand(tb.shape)\n",
    "                \n",
    "            if xb.shape[0] == 1 and yb.shape[0] > 1:\n",
    "                # Растягиваем xb до размера yb\n",
    "                xb = xb.expand(yb.shape)\n",
    "            elif yb.shape[0] == 1 and xb.shape[0] > 1:\n",
    "                # Растягиваем yb до размера xb\n",
    "                yb = yb.expand(xb.shape)\n",
    "            \n",
    "            # Теперь все тензоры должны иметь одинаковый размер в первом измерении\n",
    "            u_pred = self.model(tb, xb, yb)\n",
    "            loss += torch.mean(u_pred**2)\n",
    "            \n",
    "        return loss / len(tb_list)\n",
    "\n",
    "\n",
    "# Функция шага оптимизации\n",
    "def update_model(model, optimizer, train_data):\n",
    "    optimizer.zero_grad()\n",
    "    loss = DiffusionLoss(model)(*train_data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "y3OErz7bN_5O"
   },
   "source": [
    "## 2. Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1660882526334,
     "user": {
      "displayName": "Seungtae Nam",
      "userId": "06693906068580730486"
     },
     "user_tz": -540
    },
    "id": "VVY7wtfBN_5O"
   },
   "outputs": [],
   "source": [
    "def spinn_train_generator_diffusion3d(nc, seed=None):\n",
    "    # Setup random seed\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    # colocation points\n",
    "    tc = torch.rand(nc, 1)\n",
    "    xc = torch.rand(nc, 1) * 2 - 1  # uniform from -1 to 1\n",
    "    yc = torch.rand(nc, 1) * 2 - 1  # uniform from -1 to 1\n",
    "    \n",
    "    # initial points\n",
    "    ti = torch.zeros(nc, 1)\n",
    "    xi = xc\n",
    "    yi = yc\n",
    "    \n",
    "    # Create meshgrid for initial conditions\n",
    "    xi_flat = xi.flatten()\n",
    "    yi_flat = yi.flatten()\n",
    "    xi_mesh, yi_mesh = torch.meshgrid(xi_flat, yi_flat, indexing='ij')\n",
    "    \n",
    "    # Compute initial conditions\n",
    "    ui = 0.25 * torch.exp(-((xi_mesh - 0.3)**2 + (yi_mesh - 0.2)**2) / 0.1) + \\\n",
    "         0.4 * torch.exp(-((xi_mesh + 0.5)**2 + (yi_mesh + 0.1)**2) * 15) + \\\n",
    "         0.3 * torch.exp(-(xi_mesh**2 + (yi_mesh + 0.5)**2) * 20)\n",
    "    \n",
    "    # boundary points (hard-coded)\n",
    "    tb = [tc, tc, tc, tc]\n",
    "    xb = [torch.tensor([[-1.]], dtype=torch.float32),  # форма [1, 1]\n",
    "        torch.tensor([[1.]], dtype=torch.float32),   # форма [1, 1]\n",
    "        xc,                                          # форма [1000, 1]\n",
    "        xc]                                          # форма [1000, 1]\n",
    "    yb = [yc,                                          # форма [1000, 1]\n",
    "        yc,                                          # форма [1000, 1]\n",
    "        torch.tensor([[-1.]], dtype=torch.float32),  # форма [1, 1]\n",
    "        torch.tensor([[1.]], dtype=torch.float32)]   # форма [1, 1]\n",
    "    \n",
    "    return tc, xc, yc, ti, xi, yi, ui, tb, xb, yb\n",
    "\n",
    "\n",
    "def spinn_test_generator_diffusion3d(nc_test, data_dir=\"/home/user/SPINN_PyTorch/data/diffusion3d\"):\n",
    "    \"\"\"\n",
    "    Генерирует тестовые данные для трехмерной диффузии на основе предварительно \n",
    "    сохраненных файлов решений.\n",
    "    \n",
    "    Args:\n",
    "        nc_test: Количество тестовых точек (для совместимости с интерфейсом)\n",
    "        data_dir: Директория с сохраненными файлами решений\n",
    "        \n",
    "    Returns:\n",
    "        Кортеж с данными (t, x, y, z, u_gt, tm, xm, ym, zm)\n",
    "    \"\"\"\n",
    "    \n",
    "    u_gt = []\n",
    "    tt = 0.0\n",
    "    \n",
    "    # Загружаем сохраненные решения для разных моментов времени\n",
    "    for _ in range(101):\n",
    "        file_path = os.path.join(data_dir, f'heat_gaussian_{tt:.2f}.npy')\n",
    "        u_gt.append(torch.from_numpy(np.load(file_path)))\n",
    "        tt += 0.01\n",
    "    \n",
    "    u_gt = torch.stack(u_gt)\n",
    "    \n",
    "    # Создаем сетки для координат\n",
    "    t = torch.linspace(0.0, 1.0, u_gt.shape[0])\n",
    "    x = torch.linspace(-1.0, 1.0, u_gt.shape[1])\n",
    "    y = torch.linspace(-1.0, 1.0, u_gt.shape[2])\n",
    "    \n",
    "    # Проверяем размерность данных\n",
    "    if len(u_gt.shape) > 3:  # 3D case (t, x, y, z)\n",
    "        z = torch.linspace(-1.0, 1.0, u_gt.shape[3])\n",
    "    else:  # 2D case (t, x, y)\n",
    "        z = torch.tensor([0.0])  # Одна точка для z\n",
    "    \n",
    "    # Отключаем отслеживание градиентов для координатных сеток\n",
    "    t = t.detach()\n",
    "    x = x.detach()\n",
    "    y = y.detach()\n",
    "    z = z.detach()\n",
    "    \n",
    "    # Создаем меш-сетки\n",
    "    if len(u_gt.shape) > 3:  # 3D case (t, x, y, z)\n",
    "        tm, xm, ym, zm = torch.meshgrid(t, x, y, z, indexing='ij')\n",
    "    else:  # 2D case (t, x, y)\n",
    "        tm, xm, ym = torch.meshgrid(t, x, y, indexing='ij')\n",
    "        # Создаем фиктивную координату z для совместимости с 3D моделью\n",
    "        zm = torch.zeros_like(ym)\n",
    "        # Добавляем фиктивное измерение z к u_gt\n",
    "        u_gt = u_gt.unsqueeze(-1)\n",
    "    \n",
    "    # Форматируем данные для входа в модель\n",
    "    t_flat = t.reshape(-1)\n",
    "    x_flat = x.reshape(-1)\n",
    "    y_flat = y.reshape(-1)\n",
    "    z_flat = z.reshape(-1) if len(z.shape) > 0 else z\n",
    "    u_gt_flat = u_gt.reshape(-1)\n",
    "    \n",
    "    return t_flat, x_flat, y_flat, z_flat, u_gt_flat, tm, xm, ym, zm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wEWeH3ZFN_5P"
   },
   "source": [
    "## 3. Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1660882528274,
     "user": {
      "displayName": "Seungtae Nam",
      "userId": "06693906068580730486"
     },
     "user_tz": -540
    },
    "id": "cLX1oaDUN_5P"
   },
   "outputs": [],
   "source": [
    "def relative_l2(u_pred, u_true):\n",
    "    return torch.sqrt(torch.sum((u_pred - u_true)**2) / torch.sum(u_true**2))\n",
    "\n",
    "\n",
    "# Функция для визуализации результатов\n",
    "def plot_diffusion3d(t, x, y, u_pred, u_gt=None):\n",
    "    \"\"\"\n",
    "    Визуализирует решение уравнения диффузии\n",
    "    \n",
    "    Аргументы:\n",
    "        t, x, y: координаты точек\n",
    "        u_pred: предсказанное решение\n",
    "        u_gt: точное решение (если доступно)\n",
    "    \"\"\"\n",
    "    # Выбираем несколько временных срезов для визуализации\n",
    "    time_slices = [0, len(t)//4, len(t)//2, 3*len(t)//4, -1]\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, t_idx in enumerate(time_slices):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        \n",
    "        # Извлекаем данные для выбранного временного среза\n",
    "        t_slice = t[t_idx].item()\n",
    "        u_slice = u_pred[t_idx]\n",
    "        \n",
    "        # Создаем 2D тепловую карту для данного временного среза\n",
    "        plt.pcolormesh(x[t_idx], y[t_idx], u_slice, cmap='viridis', shading='auto')\n",
    "        plt.colorbar(label='u')\n",
    "        plt.title(f't = {t_slice:.2f}')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "    \n",
    "    # Если доступно точное решение, показываем ошибку на последнем графике\n",
    "    if u_gt is not None:\n",
    "        plt.subplot(2, 3, 6)\n",
    "        error = torch.abs(u_pred - u_gt)\n",
    "        error_mean = error.mean().item()\n",
    "        error_max = error.max().item()\n",
    "        \n",
    "        plt.pcolormesh(x[-1], y[-1], error[-1], cmap='hot', shading='auto')\n",
    "        plt.colorbar(label='Error')\n",
    "        plt.title(f'Error (mean: {error_mean:.2e}, max: {error_max:.2e})')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9Q3WgLq_N_5P"
   },
   "source": [
    "## 4. Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "executionInfo": {
     "elapsed": 326,
     "status": "ok",
     "timestamp": 1660882530315,
     "user": {
      "displayName": "Seungtae Nam",
      "userId": "06693906068580730486"
     },
     "user_tz": -540
    },
    "id": "VHtJazHuN_5Q"
   },
   "outputs": [],
   "source": [
    "def main(NC, NC_TEST, SEED, LR, EPOCHS, N_LAYERS, FEATURES, LOG_ITER, ALPHA=0.05):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.manual_seed(SEED)\n",
    "    \n",
    "    feat_sizes = [FEATURES] * N_LAYERS\n",
    "    model = SPINN(feat_sizes, alpha=ALPHA).to(device)\n",
    "    criterion = DiffusionLoss(model)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # Списки для хранения значений лоссов\n",
    "    loss_history = []\n",
    "    residual_loss_history = []\n",
    "    initial_loss_history = []\n",
    "    boundary_loss_history = []\n",
    "    error_history = []\n",
    "    \n",
    "    # Используем существующие функции генерации данных\n",
    "    train_data = spinn_train_generator_diffusion3d(NC, seed=SEED)\n",
    "    \n",
    "    # Обработка данных перед отправкой на устройство\n",
    "    tc, xc, yc, ti, xi, yi, ui, tb, xb, yb = train_data\n",
    "    \n",
    "    # Перемещаем данные на устройство\n",
    "    tc = tc.to(device)\n",
    "    xc = xc.to(device)\n",
    "    yc = yc.to(device)\n",
    "    ti = ti.to(device)\n",
    "    xi = xi.to(device)\n",
    "    yi = yi.to(device)\n",
    "    ui = ui.to(device)\n",
    "    tb = [t.to(device) for t in tb]\n",
    "    xb = [x.to(device) for x in xb]\n",
    "    yb = [y.to(device) for y in yb]\n",
    "    \n",
    "    # Объединяем данные обратно\n",
    "\n",
    "    train_data = (tc, xc, yc, ti, xi, yi, ui, tb, xb, yb)\n",
    "    \n",
    "    # Загрузка тестовых данных\n",
    "    t_test, x_test, y_test, z_test, u_gt, tm, xm, ym, zm = spinn_test_generator_diffusion3d(NC_TEST)\n",
    "    t_test = t_test.to(device)\n",
    "    x_test = x_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    u_gt = u_gt.to(device)\n",
    "    \n",
    "    # Проверка размерности тестовых данных\n",
    "    if t_test.shape[0] != x_test.shape[0] or t_test.shape[0] != y_test.shape[0]:\n",
    "        # Если разные размеры, создаем сетку координат для оценки\n",
    "        n_points = u_gt.shape[0]\n",
    "        t_grid = t_test.reshape(-1, 1).repeat(1, n_points).reshape(-1)\n",
    "        x_grid = x_test.repeat(n_points)\n",
    "        y_grid = y_test.repeat(n_points)\n",
    "        t_test, x_test, y_test = t_grid, x_grid, y_grid\n",
    "    \n",
    "    pbar = trange(1, EPOCHS + 1)\n",
    "    best_error = float('inf')\n",
    "    \n",
    "    for e in pbar:\n",
    "        if e % 100 == 0:\n",
    "            # Обновляем обучающие данные каждые 100 эпох\n",
    "            train_data = spinn_train_generator_diffusion3d(NC, seed=SEED+e)\n",
    "            \n",
    "            # Обработка новых данных\n",
    "            tc, xc, yc, ti, xi, yi, ui, tb, xb, yb = train_data\n",
    "            \n",
    "            # Перемещаем данные на устройство\n",
    "            tc = tc.to(device)\n",
    "            xc = xc.to(device)\n",
    "            yc = yc.to(device)\n",
    "            ti = ti.to(device)\n",
    "            xi = xi.to(device)\n",
    "            yi = yi.to(device)\n",
    "            ui = ui.to(device)\n",
    "            tb = [t.to(device) for t in tb]\n",
    "            xb = [x.to(device) for x in xb]\n",
    "            yb = [y.to(device) for y in yb]\n",
    "            \n",
    "            # Объединяем данные обратно\n",
    "            train_data = (tc, xc, yc, ti, xi, yi, ui, tb, xb, yb)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Распаковываем данные\n",
    "        tc, xc, yc, ti, xi, yi, ui, tb, xb, yb = train_data\n",
    "        \n",
    "        # Вычисляем компоненты функции потерь\n",
    "        loss_residual = criterion.residual_loss(tc, xc, yc)\n",
    "        loss_initial = criterion.initial_loss(ti, xi, yi, ui)\n",
    "        loss_boundary = criterion.boundary_loss(tb, xb, yb)\n",
    "        \n",
    "        # Общие потери\n",
    "        loss = loss_residual + loss_initial + loss_boundary\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Сохраняем значения лоссов\n",
    "        loss_history.append(loss.item())\n",
    "        residual_loss_history.append(loss_residual.item())\n",
    "        initial_loss_history.append(loss_initial.item())\n",
    "        boundary_loss_history.append(loss_boundary.item())\n",
    "        \n",
    "        if e % LOG_ITER == 0:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                # Вычисляем предсказание на тестовых данных\n",
    "                u_pred = model(t_test, x_test, y_test)\n",
    "                print(\"u_pred.shape\", u_pred.shape)\n",
    "                print(\"u_gt.shape\", u_gt.shape)\n",
    "                print(\"tm.shape\", tm.shape)\n",
    "                error = relative_l2(u_pred, u_gt)\n",
    "                error_history.append(error.item())\n",
    "                \n",
    "                display.clear_output(wait=True)\n",
    "                \n",
    "                # Сохраняем лучший результат\n",
    "                if error < best_error:\n",
    "                    best_error = error\n",
    "                    # Визуализация решения\n",
    "                    t_slice_indices = [0, 25, 50, 75, 100]  # Индексы временных срезов\n",
    "                    print(\"u_pred.shape\", u_pred.shape)\n",
    "                    print(\"u_gt.shape\", u_gt.shape)\n",
    "                    print(\"tm.shape\", tm.shape)\n",
    "                    plot_diffusion_solution(tm, xm, ym, u_pred.reshape(tm.shape), u_gt.reshape(tm.shape), \n",
    "                                           t_slice_indices)\n",
    "                \n",
    "                # Визуализация лоссов\n",
    "                plt.figure(figsize=(15, 5))\n",
    "                plt.subplot(121)\n",
    "                plt.semilogy(loss_history, label='Total Loss')\n",
    "                plt.semilogy(residual_loss_history, label='Residual Loss')\n",
    "                plt.semilogy(initial_loss_history, label='Initial Loss')\n",
    "                plt.semilogy(boundary_loss_history, label='Boundary Loss')\n",
    "                plt.grid(True)\n",
    "                plt.legend()\n",
    "                plt.xlabel('Iteration')\n",
    "                plt.ylabel('Loss (log scale)')\n",
    "                plt.title('Training Losses')\n",
    "                \n",
    "                plt.subplot(122)\n",
    "                plt.semilogy(range(0, len(error_history) * LOG_ITER, LOG_ITER), error_history, 'r-', label='Relative L2 Error')\n",
    "                plt.grid(True)\n",
    "                plt.legend()\n",
    "                plt.xlabel('Iteration')\n",
    "                plt.ylabel('Error (log scale)')\n",
    "                plt.title('Relative L2 Error')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                pbar.set_description(\n",
    "                    f'Loss: {loss.item():.2e} '\n",
    "                    f'(R: {loss_residual.item():.2e}, '\n",
    "                    f'I: {loss_initial.item():.2e}, '\n",
    "                    f'B: {loss_boundary.item():.2e}), '\n",
    "                    f'Error: {error.item():.2e}'\n",
    "                )\n",
    "                model.train()\n",
    "    \n",
    "    print(f'\\nTraining completed! Best error: {best_error:.2e}')\n",
    "    \n",
    "    # Финальная визуализация всех лоссов\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(121)\n",
    "    plt.semilogy(loss_history, label='Total Loss')\n",
    "    plt.semilogy(residual_loss_history, label='Residual Loss')\n",
    "    plt.semilogy(initial_loss_history, label='Initial Loss')\n",
    "    plt.semilogy(boundary_loss_history, label='Boundary Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss (log scale)')\n",
    "    plt.title('Final Training Losses')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.semilogy(range(0, len(error_history) * LOG_ITER, LOG_ITER), error_history, 'r-', label='Relative L2 Error')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Error (log scale)')\n",
    "    plt.title('Final Relative L2 Error')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, best_error, error_history\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eCdzoogAN_5Q"
   },
   "source": [
    "## 5. Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 159365,
     "status": "ok",
     "timestamp": 1660882219515,
     "user": {
      "displayName": "Seungtae Nam",
      "userId": "06693906068580730486"
     },
     "user_tz": -540
    },
    "id": "j-DGXwqYN_5Q",
    "outputId": "2a4e9df1-378f-460e-cb99-70613412a8da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 999/10000 [00:37<05:38, 26.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_pred.shape torch.Size([101])\n",
      "u_gt.shape torch.Size([1030301])\n",
      "tm.shape torch.Size([101, 101, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (101) must match the size of tensor b (1030301) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[122]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      1\u001b[39m PARAMS = {\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mNC\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1000\u001b[39m,        \u001b[38;5;66;03m# количество точек коллокации\u001b[39;00m\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mNC_TEST\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1000\u001b[39m,   \u001b[38;5;66;03m# количество тестовых точек\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mLOG_ITER\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1000\u001b[39m,  \u001b[38;5;66;03m# частота логирования\u001b[39;00m\n\u001b[32m     10\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m model, best_error, error_history = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mPARAMS\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[121]\u001b[39m\u001b[32m, line 111\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(NC, NC_TEST, SEED, LR, EPOCHS, N_LAYERS, FEATURES, LOG_ITER, ALPHA)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mu_gt.shape\u001b[39m\u001b[33m\"\u001b[39m, u_gt.shape)\n\u001b[32m    110\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtm.shape\u001b[39m\u001b[33m\"\u001b[39m, tm.shape)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m error = \u001b[43mrelative_l2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_gt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m error_history.append(error.item())\n\u001b[32m    114\u001b[39m display.clear_output(wait=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[116]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mrelative_l2\u001b[39m\u001b[34m(u_pred, u_true)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mrelative_l2\u001b[39m(u_pred, u_true):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.sqrt(torch.sum((\u001b[43mu_pred\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_true\u001b[49m)**\u001b[32m2\u001b[39m) / torch.sum(u_true**\u001b[32m2\u001b[39m))\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (101) must match the size of tensor b (1030301) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "PARAMS = {\n",
    "    'NC': 1000,        # количество точек коллокации\n",
    "    'NC_TEST': 1000,   # количество тестовых точек\n",
    "    'SEED': 42,        # случайное зерно\n",
    "    'LR': 1e-3,        # скорость обучения\n",
    "    'EPOCHS': 10000,   # количество эпох\n",
    "    'N_LAYERS': 4,     # количество слоев\n",
    "    'FEATURES': 100,   # количество нейронов в слое\n",
    "    'LOG_ITER': 1000,  # частота логирования\n",
    "}\n",
    "\n",
    "\n",
    "model, best_error, error_history = main(**PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6878677606582642,\n",
       " 0.45009270310401917,\n",
       " 0.35234466195106506,\n",
       " 0.29060640931129456,\n",
       " 0.22788578271865845,\n",
       " 0.1717708259820938,\n",
       " 0.13801142573356628,\n",
       " 0.11588618159294128,\n",
       " 0.09456562250852585,\n",
       " 0.08465206623077393]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "spinn_demo.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
